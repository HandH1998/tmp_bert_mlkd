run.sh: line 19:  1905 Terminated              python -u run_glue.py --model_type bert --model_name_or_path $MODEL_PATH --task_name $TASK_NAME --do_train --do_eval --do_lower_case --data_dir ../../data/glue_data/$TASK_NAME/ --max_seq_length 128 --per_gpu_train_batch_size 32 --learning_rate 2e-5 --num_train_epochs 4.0 --save_steps 2000 --output_dir ../../model/BERT-EMD/fine_tuned_pretrained_model/$TASK_NAME/on_original_data/ --evaluate_during_training --overwrite_output_dir > QQP_fine_tune.log 2>&1
run.sh: line 20: 1: command not found
run.sh: line 39:  1938 Terminated              python -u run_glue.py --model_type bert --model_name_or_path $MODEL_PATH --task_name $TASK_NAME --do_train --do_eval --do_lower_case --data_dir ../../data/glue_data/$TASK_NAME/ --max_seq_length 128 --per_gpu_train_batch_size 32 --learning_rate 2e-5 --num_train_epochs 6.0 --save_steps 100 --output_dir ../../model/BERT-EMD/fine_tuned_pretrained_model/$TASK_NAME/on_original_data/ --evaluate_during_training --overwrite_output_dir > QQP_fine_tune.log 2>&1
run.sh: line 58:  1950 Terminated              python -u run_glue.py --model_type bert --model_name_or_path $MODEL_PATH --task_name $TASK_NAME --do_train --do_eval --do_lower_case --data_dir ../../data/glue_data/$TASK_NAME/ --max_seq_length 128 --per_gpu_train_batch_size 32 --learning_rate 2e-5 --num_train_epochs 6.0 --save_steps 100 --output_dir ../../model/BERT-EMD/fine_tuned_pretrained_model/$TASK_NAME/on_original_data/ --evaluate_during_training --overwrite_output_dir > STS-B_fine_tune.log 2>&1
run.sh: line 19:  1972 Terminated              python -u run_glue.py --model_type bert --model_name_or_path $MODEL_PATH --task_name $TASK_NAME --do_train --do_eval --do_lower_case --data_dir ../../data/glue_data/$TASK_NAME/ --max_seq_length 128 --per_gpu_train_batch_size 32 --learning_rate 2e-5 --num_train_epochs 4.0 --save_steps 2000 --output_dir ../../model/BERT-EMD/fine_tuned_pretrained_model/$TASK_NAME/on_original_data/ --evaluate_during_training --overwrite_output_dir > MRPC_fine_tune.log 2>&1
run.sh: line 19:  2002 Terminated              python -u run_glue.py --model_type bert --model_name_or_path $MODEL_PATH --task_name $TASK_NAME --do_train --do_eval --do_lower_case --data_dir ../../data/glue_data/$TASK_NAME/ --max_seq_length 128 --per_gpu_train_batch_size 32 --learning_rate 2e-5 --num_train_epochs 4.0 --save_steps 2000 --output_dir ../../model/BERT-EMD/fine_tuned_pretrained_model/$TASK_NAME/on_original_data/ --evaluate_during_training --overwrite_output_dir > MRPC_fine_tune.log 2>&1
run.sh: line 19:  2052 Terminated              python -u run_glue.py --model_type bert --model_name_or_path $MODEL_PATH --task_name $TASK_NAME --do_train --do_eval --do_lower_case --data_dir ../../data/glue_data/$TASK_NAME/ --max_seq_length 128 --per_gpu_train_batch_size 32 --learning_rate 2e-5 --num_train_epochs 4.0 --save_steps 2000 --output_dir ../../model/BERT-EMD/fine_tuned_pretrained_model/$TASK_NAME/on_original_data/ --evaluate_during_training --overwrite_output_dir > MRPC_fine_tune.log 2>&1
run.sh: line 38:  2194 Terminated              python -u run_glue.py --model_type bert --model_name_or_path $MODEL_PATH --task_name $TASK_NAME --do_train --do_eval --do_lower_case --data_dir ../../data/glue_data/$TASK_NAME/ --max_seq_length 128 --per_gpu_train_batch_size 32 --learning_rate 2e-5 --num_train_epochs 6.0 --save_steps 100 --output_dir ../../model/BERT-EMD/fine_tuned_pretrained_model/$TASK_NAME/on_original_data/ --evaluate_during_training --overwrite_output_dir > QQP_fine_tune.log 2>&1
Terminated
